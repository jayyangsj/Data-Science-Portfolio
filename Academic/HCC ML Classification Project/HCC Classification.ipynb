{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats as st\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TASK 1 ############################\n",
    "\n",
    "df_train = pd.read_csv('hcc_train.csv') # has no ID col, no col names, has class col\n",
    "df_train.shape\n",
    "df_train.columns\n",
    "\n",
    "df_test = pd.read_csv('hcc_test.csv')  # has ID col for result submission, no class col\n",
    "df_test.shape\n",
    "df_test.columns\n",
    "\n",
    "df = pd.read_csv('hcc-data-complete-balanced.csv') # has no ID, has col names, has class col\n",
    "df.shape\n",
    "df.columns\n",
    "\n",
    "# replace training set column names by the column names of the complete set since they have the same columns arranged in the same order\n",
    "# change training set column names\n",
    "df_train.columns = df.columns \n",
    "\n",
    "# change testing set column names\n",
    "colnames = ['id']\n",
    "for cols in list(df.columns[:-1]):\n",
    "    colnames.append(cols)\n",
    "df_test.columns = colnames  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Identify the dataset columns into nominal, categorical, continues etc. categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Use dataframe.info and dataframe.describe to get the insights about the data.\n",
    "df_train.info\n",
    "df_train.describe\n",
    "\n",
    "df_test.info\n",
    "df_test.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Find the number of null values for each columns\n",
    "df_train.isnull().sum(axis=0)\n",
    "df_test.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Know about the patients (Example of analysis for ages)\n",
    "#a. Find the oldest person \n",
    "np.max(df_train.Age)\n",
    "np.max(df_test.Age)\n",
    "\n",
    "#b. Find the youngest person\n",
    "np.min(df_train.Age)\n",
    "np.min(df_test.Age)\n",
    "\n",
    "#c. Find the average age group\n",
    "round(np.mean(df_train.Age))\n",
    "round(np.mean(df_test.Age))\n",
    "\n",
    "#d. Find median age \n",
    "np.median(df_train.Age)\n",
    "np.median(df_test.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#e. Find the relationship between the deaths and ages(the class column is your prediction variable)\n",
    "# some scatter plots\n",
    "plt.scatter(df_train.Age[df_train.Class == 1], df_train.Gender[df_train.Class == 1], s = 20, c = 'r')\n",
    "plt.scatter(df_train.Age[df_train.Class == 0], df_train.Gender[df_train.Class == 0], s = 20, c = 'b')\n",
    "plt.legend(['Lived', 'Died'], loc = 7)\n",
    "plt.title('Gender vs Age (training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Gender (1=Male;0=Female)')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df_train.Grams_day, df_train.Class == 1, s = 20, c = 'r')\n",
    "plt.scatter(df_train.Grams_day, df_train.Class == 0, s = 20, c = 'b')\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Grams of Alcohol per day')\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(df_train.Packs_year, df_train.Class == 1, s = 20, c = 'r')\n",
    "plt.scatter(df_train.Packs_year, df_train.Class == 0, s = 20, c = 'b')\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Packs of cigarets per year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more plots\n",
    "####### Death vs Grams of Age #######\n",
    "plt.figure(figsize=(5,8))\n",
    "sns.kdeplot(\n",
    "        df_train.Age[df_train.Class == 1],\n",
    "        color = 'red',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "sns.kdeplot(\n",
    "        df_train.Age[df_train.Class == 0],\n",
    "        color = 'blue',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Age (training set)')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0, 125)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f. Find the age groups whose survival rate is the largest \n",
    "bins = [0, 20, 50, 75, 100]\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Patients Count')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "out = pd.cut(df_train.Age[df_train.Class == 1], bins = bins, include_lowest = True)\n",
    "ax = out.value_counts(sort = False).plot.bar(rot = 0, color = 'r', figsize = (10,10))\n",
    "out = pd.cut(df_train.Age[df_train.Class == 0], bins = bins, include_lowest = True)\n",
    "ax = out.value_counts(sort = False).plot.bar(rot = 0, color = 'b', figsize = (10,10))\n",
    "\n",
    "# ANS: the highest survival rate by age group is 20 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g. Find similar relationships for at least 3-4 columns that you think can play a role in prediction\n",
    "#   (For example, Sex, alcohol consumption, etc.)\n",
    "\n",
    "####### Death vs Grams of Alcohol per day #######\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "sns.kdeplot(\n",
    "        df_train.Grams_day[df_train.Class == 1],\n",
    "        color = 'red',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "sns.kdeplot(\n",
    "        df_train.Grams_day[df_train.Class == 0],\n",
    "        color = 'blue',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Grams of Alcohol per day (training)')\n",
    "plt.xlabel('Grams of Alcohol per day')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0, np.max(df_train.Grams_day))\n",
    "plt.show()\n",
    "\n",
    "####### Death vs Packs of cigarets per year #######\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "sns.kdeplot(\n",
    "        df_train.Packs_year[df_train.Class == 1],\n",
    "        color = 'red',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "sns.kdeplot(\n",
    "        df_train.Packs_year[df_train.Class == 0],\n",
    "        color = 'blue',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Packs of cigarettes per year (training)')\n",
    "plt.xlabel('Packs of cigarettes per year')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0, 100)\n",
    "plt.show()\n",
    "\n",
    "####### Death vs Performance #######\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "sns.kdeplot(\n",
    "        df_train.PS[df_train.Class == 1],\n",
    "        color = 'red',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "sns.kdeplot(\n",
    "        df_train.PS[df_train.Class == 0],\n",
    "        color = 'blue',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Performance (training)')\n",
    "plt.xlabel('Performance')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0, 6)\n",
    "plt.show()\n",
    "\n",
    "####### Death vs Gender #######\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "sns.kdeplot(\n",
    "        df_train.Encephalopathy[df_train.Class == 1],\n",
    "        color = 'red',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "sns.kdeplot(\n",
    "        df_train.Encephalopathy[df_train.Class == 0],\n",
    "        color = 'blue',\n",
    "        shade = True\n",
    "        )\n",
    "\n",
    "plt.legend(['Lived', 'Died'])\n",
    "plt.title('Death vs Encephalopathy degree (training)')\n",
    "plt.xlabel('Encephalopathy degree')\n",
    "plt.ylabel('')\n",
    "plt.xlim(0, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h. Get more visuals on data distributions\n",
    "\n",
    "#  i. Use plotCorrelationMatrix\n",
    "sns.set(style=\"white\")\n",
    "corr = df_train.corr()\n",
    "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.title('Correlation Plot Matrix (training)')\n",
    "\n",
    "#  ii. plotScatterMatrix\n",
    "selected_col = pd.DataFrame([df_train.Age, df_train.Gender, df_train.PS, df_train.Grams_day, df_train.Packs_year, df_train.Class])\n",
    "selected_col = np.transpose(selected_col)\n",
    "sns.set(style=\"ticks\")\n",
    "sns.pairplot(selected_col, hue=\"Class\") \n",
    "\n",
    "#  iii. plotPerColumnDistribution\n",
    "for i in df_train.columns:\n",
    "    sns.distplot(df_train[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use information from the plots to get an intuition for selecting feature variables\n",
    "#i. Find missing values\n",
    "\n",
    "#  i. Get the count of missing values\n",
    "df_train.isnull().sum(axis=0)\n",
    "np.sum(df_train.isnull().sum(axis=0))\n",
    "\n",
    "df_test.isnull().sum(axis=0)\n",
    "np.sum(df_test.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ii. Plot a heat map for missing value\n",
    "sns.heatmap(df_train.isnull(), cbar=False) #cbar set to false since it is binary \n",
    "plt.title('Missing value Heatmap (train)')\n",
    "plt.xlabel('Columns names')\n",
    "plt.ylabel('Row number')\n",
    "\n",
    "sns.heatmap(df_test.isnull(), cbar=False)\n",
    "plt.title('Missing value Heatmap (test)')\n",
    "plt.xlabel('Columns names')\n",
    "plt.ylabel('Row number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#j. Applying a different technique to handle missing values (For each technique verify your prediction results)\n",
    "\n",
    "# backing up dataframes\n",
    "df_train_backup = df_train\n",
    "df_test_backup = df_test\n",
    "\n",
    "#  i. Use dropna\n",
    "df_train_noNaN = df_train.dropna()\n",
    "df_train_noNaN.shape # dropping na is a disaster\n",
    "\n",
    "df_test_noNaN = df_test.dropna()\n",
    "df_test_noNaN.shape # dropping na is a disaster\n",
    "\n",
    "#  ii. Use replace na with zero or max value\n",
    "df_train_0NaN = df_train.fillna(0)\n",
    "df_train_0NaN.shape\n",
    "df_test_0NaN = df_test.fillna(0) \n",
    "\n",
    "#  iii. Use replace na with mean \n",
    "df_train_meanNaN = df_train.fillna(df_train.mean())  # Go pandas!\n",
    "df_test_meanNaN = df_test.fillna(df_test.mean())\n",
    "\n",
    "#  iv. Search for additional techniques to handle null values,\n",
    "#       excluding the above three and test. (Include all the techniques that you used in your report.)\n",
    "\n",
    "# -- Handle Missing Value by Imputation --\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'median') # imputaion by median\n",
    "imputer = imputer.fit(df_train)\n",
    "df_train_imp = imputer.transform(df_train)\n",
    "df_train_imp = pd.DataFrame(df_train_imp)\n",
    "df_train_imp.columns = df.columns\n",
    "\n",
    "imputer = imputer.fit(df_test)\n",
    "df_test_imp = imputer.transform(df_test)\n",
    "df_test_imp = pd.DataFrame(df_test_imp)\n",
    "df_test_imp.columns = df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#l. Applying the regression models that you think is most suited for this problem.\n",
    "\n",
    "# ----------------- verify predictions using Random Forest on differently treated missing values ----------------- \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "##### l.1 Deleted NaN #####\n",
    "\n",
    "# deleting all rows that have NaN will result in tiny datasets\n",
    "\n",
    "X_train = pd.DataFrame(df_train_noNaN.iloc[:, 0:-1])\n",
    "#X_train = np.transpose(X_train)\n",
    "X_train.shape\n",
    "\n",
    "y_train = df_train_noNaN.Class[X_train.index]\n",
    "y_train.shape\n",
    "\n",
    "X_test = df_test_noNaN.iloc[:, 1:] # drop ID column\n",
    "X_test.shape\n",
    "\n",
    "# fitting\n",
    "classifier = RandomForestClassifier(bootstrap = True, n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#accuracy score\n",
    "classifier.score(X_train, y_train)\n",
    " \n",
    "# Predicting the Test set results\n",
    "y_pred_noNaN = classifier.predict(X_test)  # prediction\n",
    "print(y_pred_noNaN)\n",
    "\n",
    "##### l.2 Replace NaN by 0 #####\n",
    "#num = np.random.choice(range(df_train.shape[0]), df_test.shape[0], replace = True)  # bootstrap sampling\n",
    "\n",
    "#help(np.random.choice)\n",
    "X_train = df_train_0NaN.iloc[:, 0:-1]\n",
    "y_train = df_train_0NaN.Class\n",
    "X_test = df_test_0NaN.iloc[:, 1:]\n",
    "\n",
    "# fitting\n",
    "classifier = RandomForestClassifier(bootstrap = True, n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#accuracy score\n",
    "classifier.score(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_0NaN = classifier.predict(X_test)  # prediction\n",
    "\n",
    "\n",
    "##### l.3 Replace NaN by mean ##### \n",
    "#num = np.random.choice(range(df_train.shape[0]), df_test.shape[0], replace = True)  # bootstrap sampling\n",
    "\n",
    "X_train = df_train_meanNaN.iloc[:, 0:-1]\n",
    "y_train = df_train_meanNaN.Class\n",
    "X_test = df_test_meanNaN.iloc[:, 1:]\n",
    "\n",
    "# fitting\n",
    "classifier = RandomForestClassifier(bootstrap = True, n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#accuracy score\n",
    "classifier.score(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred_meanNaN = classifier.predict(X_test)  # prediction\n",
    "\n",
    "\n",
    "## l.4 imputate NaN by with median (this step overlaps with applying random forest model)\n",
    "\n",
    "# all the classification models below will use imputed training and testing datasets by median\n",
    "X_train = df_train_imp.iloc[:, 0:-1]\n",
    "y_train = df_train_imp.Class\n",
    "X_test = df_test_imp.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Applying Regression Models ##################################\n",
    "# ----------------- Random Forest ----------------- \n",
    "\n",
    "# fitting\n",
    "classifier_RF = RandomForestClassifier(bootstrap = True, n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "classifier_RF.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set \n",
    "classifier_RF.score(X_train, y_train)  \n",
    "RF_accuracy = round(classifier_RF.score(X_train, y_train) * 100, 2) # 100% accuracy.\n",
    "RF_accuracy\n",
    "\n",
    "# Predicting\n",
    "y_pred_RF = classifier_RF.predict(X_test)  # prediction (this is used for submission)\n",
    "\n",
    "\n",
    "# ----------------- Decision Tree ----------------- \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fitting\n",
    "classifier_DT = DecisionTreeClassifier()\n",
    "classifier_DT.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "DT_accuracy = round(classifier_DT.score(X_train, y_train) * 100, 2) # 100% accuracy.\n",
    "DT_accuracy\n",
    "\n",
    "# predicting\n",
    "y_pred_DT = classifier_DT.predict(X_test)\n",
    "\n",
    "\n",
    "# ----------------- Naive Bayes ----------------- \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# fitting\n",
    "classifier_NB = GaussianNB()\n",
    "classifier_NB.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "NB_accuracy = round(classifier_NB.score(X_train, y_train) * 100, 2)\n",
    "NB_accuracy\n",
    "\n",
    "# predicting\n",
    "Y_pred_NB = classifier_NB.predict(X_test)\n",
    "\n",
    "\n",
    "# ----------------- SVM ----------------- \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# fitting\n",
    "classifier_SVC = SVC()\n",
    "classifier_SVC.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "SVC_accuracy = round(classifier_SVC.score(X_train, y_train) * 100, 2)\n",
    "SVC_accuracy\n",
    "\n",
    "# predicting\n",
    "Y_pred_SVC = classifier_SVC.predict(X_test)\n",
    "\n",
    "\n",
    "#m. At least one of the models used to compute should be your own implementation using NumPy.\n",
    "\n",
    "# ----------------- Logistic Regression (mannual implementation) ----------------- \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fitting\n",
    "classifier_log = LogisticRegression()\n",
    "classifier_log.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "log_accuracy = round(classifier_log.score(X_train, y_train) * 100, 2)\n",
    "log_accuracy\n",
    "\n",
    "# predicting\n",
    "Y_pred_log = classifier_log.predict(X_test)\n",
    "\n",
    "\n",
    "# ----------------- Perceptron ----------------- \n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# fitting\n",
    "classifier_P = Perceptron(max_iter=5)\n",
    "classifier_P.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "P_accuracy = round(classifier_P.score(X_train, y_train) * 100, 2)\n",
    "P_accuracy\n",
    "\n",
    "# predicting\n",
    "Y_pred_P = classifier_P.predict(X_test)\n",
    "\n",
    "# ----------------- SGD ----------------- \n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# fitting\n",
    "classifier_SGD = linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "classifier_SGD.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "SGD_accuracy = round(classifier_SGD.score(X_train, y_train) * 100, 2)\n",
    "SGD_accuracy\n",
    "\n",
    "# predicting\n",
    "Y_pred_SGD = classifier_SGD.predict(X_test)\n",
    "\n",
    "\n",
    "# ----------------- KNN ----------------- \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# fitting\n",
    "classifier_KNN = KNeighborsClassifier(n_neighbors = 3)\n",
    "classifier_KNN.fit(X_train, y_train)\n",
    "\n",
    "# accuracy score on training set\n",
    "KNN_accuracy = round(classifier_KNN.score(X_train, y_train) * 100, 2)\n",
    "KNN_accuracy\n",
    "\n",
    "# predicting\n",
    "Y_pred_KNN = classifier_KNN.predict(X_test)\n",
    "\n",
    "\n",
    "## TABLE 1. model accuracy scores in percent\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Stochastic Gradient Decent', \n",
    "              'Decision Tree'],\n",
    "    'Score': [SVC_accuracy, KNN_accuracy, log_accuracy, RF_accuracy, \n",
    "              NB_accuracy, P_accuracy, SGD_accuracy, DT_accuracy]})\n",
    "    \n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m. At least one of the models used to compute should be your own implementation using NumPy.\n",
    "# ----------------- Logistic Regression (mannual implementation) -----------------\n",
    "\n",
    "############### Functions ###############\n",
    "def genWeight(n, a, b):\n",
    "    \"\"\"This function generates n uniformly distributed weights from a to b then transpose the matrix\n",
    "        n = number of weights\n",
    "        a = lower bound of uniformly distributed interval\n",
    "        b = upper bound of uniformly distributed interval\n",
    "    \"\"\"\n",
    "    w = []\n",
    "    for i in range(n):                    # n feature columns, n weights, no noise\n",
    "        w.append(np.random.uniform(a,b))     # randomly generate uniformly distributed w's\n",
    "    w = np.reshape(w, (n, 1))             # reshape it to n by 1 to do dot product w/ x\n",
    "    return w\n",
    "# end of genWeight()\n",
    "    \n",
    "def H(X, w):  # Hypothesis function:  H(X)= 1/(1+exp{transpose(w)X}\n",
    "    \"\"\"This func returns a list of values of a logistic regression H function, H(X)\n",
    "        X = the predictor matrix.\n",
    "        p = vector of dot product of X and w\n",
    "        w = weight\n",
    "        r = number of observations\n",
    "        n,a,b see genWeights()\n",
    "    \"\"\"\n",
    "    r = X.shape[0]\n",
    "    h = []                   \n",
    "    for i in range(r):          # iterations depends on number of observations\n",
    "        p = X[i].dot(w)         # ith obs. dot weight\n",
    "        h.append( 1 / (1 + np.math.e**(-p)) )    # list of probability from H function\n",
    "    return h\n",
    "\n",
    "\n",
    "#end of H()\n",
    "\n",
    "def costF(X, y, w, h):\n",
    "    \"\"\"gradient descend for logistic function: \n",
    "        X = predictor matrix    m by # of feature cols\n",
    "        y = response matrix   m by 1\n",
    "        m = number of observations\n",
    "        cost(w) = J(w) = (-1/m)*sum( y_i*log(h_w(x_i)) + (1-y_i)log(1 - h_w(x_i)) )\n",
    "    \"\"\"\n",
    "        #cost += y[i]*math.log(H(X)[i], math.e) + (1-y[i])*math.log((1 - H(X)[i]), math.e)\n",
    "    r = X.shape[0]\n",
    "    cost = 0                     # initialize cost variable\n",
    "    for i in range(r):\n",
    "        if y[i] == 1:            # calculate cost if y = 1\n",
    "            cost += np.math.log(h[i])        # log(h_w(x_i)) if y = 1\n",
    "        elif y[i] == 0:          # calculate cost if y = 0\n",
    "            cost += np.math.log((1 - h[i]))  # log(1 - h_w(x_i)) if y = 0\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return -1*cost/r                # returns the average cost\n",
    "# end of costF()\n",
    "\n",
    "def dCostF(X, y, w, h):\n",
    "    \"\"\"This function returns the partial derivative of the cost function with respect to \n",
    "        each weight, theta_i, in the n by 1 W matrix.\n",
    "        X = predictor matrix    m by # of feature cols\n",
    "        y = response matrix   m by 1\n",
    "        h = H(X)\n",
    "        r = number of observations\n",
    "        c = number of features\n",
    "        partial derivative:  (h_theta(x_i) - y_i) * x_i_j\n",
    "    \"\"\"\n",
    "    r = X.shape[0]\n",
    "    c = X.shape[1]\n",
    "    value = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            value += (h[i] - y[i]) * X[i][j]  # partial derivative of theta_j \n",
    "    \n",
    "    return float(value/r)      # return the average\n",
    "# end of dCostf()\n",
    "\n",
    "def gradDLogistic(X, y, w, h, alpha, runs):\n",
    "    \"\"\"This function performs gradient descend to estimate weight for logistic regression\n",
    "        w = weight\n",
    "        n, a, b:  see genWeight()\n",
    "        alpha = learning rate\n",
    "        X, y: X predictor and response matrix, respectively. see costF() and dCostF()        \n",
    "        GradientDescend: theta_j := theta_j - alpha * partial_w_j ( J(theta) )\n",
    "    \"\"\"\n",
    "    theta = w\n",
    "    for i in range(runs):                           # number of iterations for gradient descend\n",
    "        h = H(X, theta)                             # update hypothesis function, H(X)\n",
    "        h_range = (min(h), max(h))                  # update interval of probabilities from H(X)\n",
    "        #j = costF(X, y, theta, h)                   # update cost function\n",
    "        dj = dCostF(X, y, theta, h)                 # update partial derivatives\n",
    "        theta = theta - alpha * dj                  # update weight\n",
    "        #print(\"iteration: {} , J(W): {}, dJ(W): {}\\nprobability range: {} \\nw: \\n{}\".format(i,j,dj,h_range,theta))\n",
    "\n",
    "    return theta                                    # return list of approximated weights\n",
    "# end of gradDLogistic()\n",
    "\n",
    "############### End of Functions ############### \n",
    "############### main() ############### \n",
    "X = np.array(df_train_imp.iloc[:, 0:-1])\n",
    "y = np.array(df_train_imp.Class)     # resposne col\n",
    "\n",
    "w = genWeight(X.shape[1], -1, 1)     # generate a 2 by 1 weight matrix randomly and uniformly from -1 to 1\n",
    "h = H(X, w)                    # list of probabilities from hypothesis function using random weights\n",
    "print(\"The current range of probabilities from Hypothesis function:\", min(h), max(h))\n",
    "theta = gradDLogistic(X,y,w,h,0.01,1000) #1000 iterations to approximate the optimal weight parameters, theta\n",
    " print(theta)\n",
    "# Plot your hypothesis function that classifies the dataset\n",
    "\n",
    "z = X.dot(theta)              # vector of values Theta*X\n",
    "print(\"range of z\", min(z), max(z))         \n",
    "h_final = 1/(1+np.math.e**(-z))  # a list of probabilities produced by H(W, theta) \n",
    "\n",
    "# plot hypothesis function using approximated weight parameters\n",
    "print(\"probability = 0.5 in H(X,theta) with approximated theta is: \" + str(0.5 in h_final))\n",
    "pred = []\n",
    "for prob in h_final:\n",
    "    if prob > 0.5:            # since 0.5 Not in H(X, theta), >0.5 is 1 and <0.5 is 0\n",
    "        pred.append(1)        # > 0.5, it's 1\n",
    "    else:\n",
    "        pred.append(0)        # < 0.5, it's 0\n",
    "\n",
    "pred = np.reshape(pred, (len(pred)))\n",
    "print('\\n')\n",
    "correct = list(pred - y).count(0) # number of correct prediction  # 0-0 and 1-1 are correct predictions\n",
    "print(\"The number of correct prediction is:\", correct, \"out of\", X.shape[0], \"observations.\")\n",
    "print(\"The accuracy is \" + str(int(correct/X.shape[0]*100)) + \"%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n. Upload your test data ​predictions​ to Kaggle competition in the correct submission format. \n",
    "\n",
    "# Submission\n",
    "submission = pd.DataFrame({'id': df_test.id, 'answer': y_pred_RF})\n",
    "submission\n",
    "\n",
    "submission.to_csv(r'hcc_submission_Yuntian_Yang.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TASK 2 ############################\n",
    "\n",
    "df = pd.read_csv('hcc-data-complete-balanced.csv') # has no ID, has class col\n",
    "df.shape\n",
    "df.columns\n",
    "\n",
    "# replace ',' by '.' in all columns\n",
    "for cols in df.columns:\n",
    "    for j in range(len(cols)):\n",
    "        if type(df[cols][j]) == str:\n",
    "            df[cols] = df[cols].str.replace(',','.').astype(float)\n",
    "\n",
    "\n",
    "#1. Split the dataset in train and test samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(df.iloc[:, 0:-1], df.Class, test_size =.265, random_state = 0) # 27% split so test sets have the same size in task 1 & 2\n",
    "\n",
    "#2. Applying the regression model that you think is most suited for this problem.\n",
    "# random forest is the most suitable\n",
    "# ----------------- Random Forest ----------------- \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(bootstrap = True, n_estimators = 100, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "classifier.score(Xtrain, Ytrain)\n",
    "\n",
    "Xtrain.shape\n",
    "Xtest.shape\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(Xtest)\n",
    "\n",
    "#3. Compare your prediction result with the first technique.\n",
    "#   Comparison technique​:  We will use confusion matrix to evaluate the performance Compute Precision,\n",
    "#   Recall and F1 score for both Task 1 and Task 2\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Ytest, y_pred)\n",
    "cm\n",
    "\n",
    "# Precision = true pos/ (true pos + false pos)\n",
    "pre = cm[1][1]  / ( cm[1][1] + cm[0][1]) \n",
    "# Recall score = true pos / (true pos + false neg)\n",
    "recal = cm[1][1] / ( cm[1][0] + cm[1][1] )\n",
    "# F1 Score = 2*Precision*Recall / (Precision + Recall)\n",
    "F1 = 2*pre*recal / (pre+recal)\n",
    "pre,recal,F1\n",
    "\n",
    "# confusion matrix for TASK1\n",
    "cm1 = confusion_matrix(Ytest, y_pred_RF)\n",
    "cm1\n",
    "# Precision = true pos/ (true pos + false pos)\n",
    "pre_1 = cm1[1][1]  / ( cm1[1][1] + cm1[0][1]) \n",
    "# Recall score = true pos / (true pos + false neg)\n",
    "recal_1 = cm1[1][1] / ( cm1[1][0] + cm1[1][1] )\n",
    "# F1 Score = 2*Precision*Recall / (Precision + Recall)\n",
    "F1_1 = 2*pre_1*recal_1 / (pre_1+recal_1)\n",
    "pre_1,recal_1,F1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ TASK 3 ############################\n",
    "#a. Apply feature transform on the features used in task 1 \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2) # 0.8454545454545455\n",
    "X_train_transform2 = poly.fit_transform(X_train)\n",
    "classifier_poly2 = LogisticRegression()\n",
    "classifier_poly2.fit(X_train_transform2, y_train)\n",
    "classifier_poly2.score(X_train_transform2, y_train)\n",
    "\n",
    "poly = PolynomialFeatures(3) # 0.7454545454545455\n",
    "X_train_transform3 = poly.fit_transform(X_train)\n",
    "classifier_poly3 = LogisticRegression()\n",
    "classifier_poly3.fit(X_train_transform3, y_train)\n",
    "classifier_poly3.score(X_train_transform3, y_train)\n",
    "\n",
    "poly = PolynomialFeatures(4) # 0.8545454545454545\n",
    "X_train_transform4 = poly.fit_transform(X_train)\n",
    "classifier_poly4 = LogisticRegression()\n",
    "classifier_poly4.fit(X_train_transform4, y_train)\n",
    "classifier_poly4.score(X_train_transform4, y_train)\n",
    "\n",
    "poly = PolynomialFeatures(5) # 0.8181818181818182\n",
    "X_train_transform5 = poly.fit_transform(X_train)\n",
    "classifier_poly5 = LogisticRegression()\n",
    "classifier_poly5.fit(X_train_transform5, y_train)\n",
    "classifier_poly5.score(X_train_transform5, y_train)\n",
    "\n",
    "#   a. Does varying the polynomial degree change your accuracy?\n",
    "# Yes, the higher the degree, the less accurate it becomes.\n",
    "\n",
    "#   b. Can you identify if your model is underfitting or overfitting? \n",
    "#      (Hint use cross-validation error and in-sample error plot to identify high bias and\n",
    "#       high variance.) Plot the relationships\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def calc_train_error(X_train, y_train, model):\n",
    "    '''returns in-sample error for already fit model.'''\n",
    "    predictions = model.predict(X_train)\n",
    "    mse = mean_squared_error(y_train, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return mse\n",
    "\n",
    "p2 = calc_train_error(X_train_transform2, y_train, classifier_poly2)\n",
    "p3 = calc_train_error(X_train_transform3, y_train, classifier_poly3)\n",
    "p4 = calc_train_error(X_train_transform4, y_train, classifier_poly4)\n",
    "p5 = calc_train_error(X_train_transform5, y_train, classifier_poly5)\n",
    "\n",
    "plt.plot(np.linspace(2,5,4),[p2,p3,p4,p5])\n",
    "plt.title('In-sample error vs degree')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('In-sample error')\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "cross_validate()\n",
    "c2 = cross_validate(classifier_poly2, X_train_transform2, y_train, cv=3)\n",
    "c3 = cross_validate(classifier_poly3, X_train_transform3, y_train, cv=3)\n",
    "c4 = cross_validate(classifier_poly4, X_train_transform4, y_train, cv=3)\n",
    "c5 = cross_validate(classifier_poly5, X_train_transform5, y_train, cv=3)\n",
    "c2,c3,c4,c5\n",
    "# shows degree 2 has highest train score and egree 4 has highest test score\n",
    "# degree 4 might be the best choice since it has the least in-sample error and the highest test_score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
